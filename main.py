# main.py
import argparse
from datetime import datetime, timedelta
import os

from crawler import get_report_list
from downloader import download_pdf
# â­ï¸ ìˆ˜ì •ëœ ë¶€ë¶„: unstructuredë¥¼ ì‚¬ìš©í•˜ëŠ” ìƒˆ í•¨ìˆ˜ë¥¼ importí•©ë‹ˆë‹¤.
from parser import convert_pdf_to_text, save_text
from summarizer import summarize_text, save_summary
from uploader import upload_file
from utils import get_data_path, get_date_str, sanitize_filename
from embedder import embed_text
from db import insert_chunk

def get_all_paths(date: datetime, filename: str, create=False):
    """í•„ìš”í•œ ëª¨ë“  íŒŒì¼ ê²½ë¡œë¥¼ ìƒì„±í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    pdf_path = os.path.join(get_data_path("raw", date, create=create), filename + ".pdf")
    txt_path = os.path.join(get_data_path("text", date, create=create), filename + ".txt")
    sum_path = os.path.join(get_data_path("summary", date, create=create), filename + ".sum") # ìš”ì•½ ê²½ë¡œ ì¶”ê°€
    return pdf_path, txt_path, sum_path

def parse_args():
    parser = argparse.ArgumentParser(description="ETF ë¦¬í¬íŠ¸ ìë™ ë¶„ì„ê¸°")
    parser.add_argument("--date", help="ë‹¨ì¼ ë‚ ì§œ ë¶„ì„ (YYYY-MM-DD)")
    parser.add_argument("--datefrom", help="ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)")
    parser.add_argument("--dateto", help="ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)")
    return parser.parse_args()

def run_for_date(target_date: datetime):
    date_str = get_date_str(target_date)
    reports = get_report_list(target_date.strftime("%Y-%m-%d"))
    if not reports:
        print(f"\nğŸ“­ {date_str} ë¦¬í¬íŠ¸ ì—†ìŒ")
        return

    print(f"\nğŸ“… {date_str} ë¦¬í¬íŠ¸ ìˆ˜: {len(reports)}")
    for i, report in enumerate(reports):
        print(f"\n{'='*40}\n{i+1}. {report['company']} - {report['title']}")
        base_filename = sanitize_filename(f"{report['company']}_{report['title']}")

        pdf_path, txt_path, sum_path = get_all_paths(target_date, base_filename, create=False)

        # 1ï¸âƒ£ PDF ë‹¤ìš´ë¡œë“œ
        if not os.path.exists(pdf_path):
            pdf_path, _, _ = get_all_paths(target_date, base_filename, create=True)
            download_pdf(
                pdf_url=report["pdf_url"],
                company=report["company"],
                date=report["date"],
                title=report["title"],
                save_path=pdf_path
            )
        else:
            print(f"ğŸ“ PDF ìˆìŒ â†’ ìŠ¤í‚µ: {os.path.basename(pdf_path)}")

        if not os.path.exists(pdf_path):
            print(f"âŒ PDF ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨, ë‹¤ìŒ ë¦¬í¬íŠ¸ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
            continue
            
        size_mb = os.path.getsize(pdf_path) / (1024 * 1024)
        print(f"ğŸ“Š PDF íŒŒì¼ í¬ê¸°: {size_mb:.2f} MB")
        upload_file(pdf_path, f"data/raw/{date_str}/{os.path.basename(pdf_path)}")

        # 2ï¸âƒ£ í…ìŠ¤íŠ¸ ì¶”ì¶œ (unstructured ì‚¬ìš©)
        if not os.path.exists(txt_path):
            _, txt_path, _ = get_all_paths(target_date, base_filename, create=True)
            try:
                # â­ï¸ ìˆ˜ì •ëœ ë¶€ë¶„: ë³€ê²½ëœ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
                text = convert_pdf_to_text(pdf_path)
                if text:
                    save_text(text, txt_path)
                else:
                    print("âŒ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                    continue
            except Exception as e:
                print(f"âŒ í…ìŠ¤íŠ¸ ì¶”ì¶œ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")
                continue
        else:
            print(f"ğŸ“ í…ìŠ¤íŠ¸ ìˆìŒ â†’ ìŠ¤í‚µ: {os.path.basename(txt_path)}")
            
        if not os.path.exists(txt_path):
            print(f"âŒ í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ì–´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue

        with open(txt_path, 'r', encoding='utf-8') as f:
            text = f.read()

        # 3ï¸âƒ£ ë¦¬í¬íŠ¸ ìš”ì•½
        if not os.path.exists(sum_path):
            print("ğŸ¤– ë¦¬í¬íŠ¸ ìš”ì•½ ìƒì„± ì¤‘...")
            _, _, sum_path = get_all_paths(target_date, base_filename, create=True)
            summary = summarize_text(text)
            
            # â­ï¸ ìš”ì•½ ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ë„ë¡ ìˆ˜ì •
            if "ìš”ì•½ ìƒì„± ì‹¤íŒ¨" in summary:
                print("âš ï¸ ìš”ì•½ì— ì‹¤íŒ¨í•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„(ì„ë² ë”©)ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
            else:
                save_summary(summary, sum_path)
                print(f"âœ… ìš”ì•½ ì™„ë£Œ: {os.path.basename(sum_path)}")
                if os.path.exists(sum_path):
                    upload_file(sum_path, f"data/summary/{date_str}/{os.path.basename(sum_path)}")
        else:
            print(f"ğŸ¤– ìš”ì•½ íŒŒì¼ ìˆìŒ â†’ ìŠ¤í‚µ: {os.path.basename(sum_path)}")

        # 4ï¸âƒ£ ì„ë² ë”© ë° DB ì €ì¥
        print("ğŸ§  ì„ë² ë”© ë° DB ì €ì¥ ì¤‘...")
        try:
            chunks_and_vectors = embed_text(text)
            if not chunks_and_vectors:
                print("âš ï¸ ìœ íš¨í•œ ì²­í¬ê°€ ì—†ì–´ ì„ë² ë”©ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                continue

            print(f"âœ… ì„ë² ë”© ì™„ë£Œ: {len(chunks_and_vectors)} chunks ìƒì„±")
            
            for idx, (chunk, vector) in enumerate(chunks_and_vectors):
                metadata = {
                    "company": report["company"],
                    "title": report["title"],
                    "date": report["date"]
                }
                insert_chunk(
                    file_id=base_filename,
                    chunk_index=idx,
                    content=chunk,
                    embedding=vector,
                    metadata=metadata
                )
            print("âœ… DB ì €ì¥ ì™„ë£Œ.")
        except Exception as e:
            print(f"ğŸš¨ ì„ë² ë”© ë˜ëŠ” DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    args = parse_args()
    if args.date:
        run_for_date(datetime.strptime(args.date, "%Y-%m-%d"))
    elif args.datefrom and args.dateto:
        start = datetime.strptime(args.datefrom, "%Y-%m-%d")
        end = datetime.strptime(args.dateto, "%Y-%m-%d")
        cur = start
        while cur <= end:
            run_for_date(cur)
            cur += timedelta(days=1)
    else:
        run_for_date(datetime.today())

